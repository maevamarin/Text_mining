<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Supervised learning | Dicours Analysis</title>
  <meta name="description" content="Chapter 7 Supervised learning | Dicours Analysis" />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Supervised learning | Dicours Analysis" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Supervised learning | Dicours Analysis" />
  
  
  

<meta name="author" content="Eugénie Mathieu, Maeva Marin, Hadrien Renger, Wajma Nazim" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="word-embedding.html"/>
<link rel="next" href="conclusion.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.15/datatables.js"></script>
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#overview-and-motivation"><i class="fa fa-check"></i><b>1.1</b> Overview and Motivation</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="eda.html"><a href="eda.html"><i class="fa fa-check"></i><b>2</b> EDA</a><ul>
<li class="chapter" data-level="2.1" data-path="eda.html"><a href="eda.html#data-acquisition"><i class="fa fa-check"></i><b>2.1</b> Data Acquisition</a><ul>
<li class="chapter" data-level="2.1.1" data-path="eda.html"><a href="eda.html#emmanuel-macron"><i class="fa fa-check"></i><b>2.1.1</b> Emmanuel Macron</a></li>
<li class="chapter" data-level="2.1.2" data-path="eda.html"><a href="eda.html#boris-johnson"><i class="fa fa-check"></i><b>2.1.2</b> Boris Johnson</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="eda.html"><a href="eda.html#tokenisation-lemmatization-cleaning"><i class="fa fa-check"></i><b>2.2</b> Tokenisation, Lemmatization &amp; Cleaning</a><ul>
<li class="chapter" data-level="2.2.1" data-path="eda.html"><a href="eda.html#emmanuel-macron-1"><i class="fa fa-check"></i><b>2.2.1</b> Emmanuel Macron</a></li>
<li class="chapter" data-level="2.2.2" data-path="eda.html"><a href="eda.html#boris-johnson-1"><i class="fa fa-check"></i><b>2.2.2</b> Boris Johnson</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="eda.html"><a href="eda.html#document-term-matrix-dtm"><i class="fa fa-check"></i><b>2.3</b> Document-Term Matrix DTM</a><ul>
<li class="chapter" data-level="2.3.1" data-path="eda.html"><a href="eda.html#table"><i class="fa fa-check"></i><b>2.3.1</b> Table</a></li>
<li class="chapter" data-level="2.3.2" data-path="eda.html"><a href="eda.html#most-frequent-words"><i class="fa fa-check"></i><b>2.3.2</b> Most frequent words</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="eda.html"><a href="eda.html#tf-idf"><i class="fa fa-check"></i><b>2.4</b> TF-IDF</a><ul>
<li class="chapter" data-level="2.4.1" data-path="eda.html"><a href="eda.html#emmanuel-macron-2"><i class="fa fa-check"></i><b>2.4.1</b> Emmanuel Macron</a></li>
<li class="chapter" data-level="2.4.2" data-path="eda.html"><a href="eda.html#boris-johnson-2"><i class="fa fa-check"></i><b>2.4.2</b> Boris Johnson</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="eda.html"><a href="eda.html#cloud-of-words"><i class="fa fa-check"></i><b>2.5</b> Cloud of Words</a><ul>
<li class="chapter" data-level="2.5.1" data-path="eda.html"><a href="eda.html#usind-dfm"><i class="fa fa-check"></i><b>2.5.1</b> Usind DFM</a></li>
<li class="chapter" data-level="2.5.2" data-path="eda.html"><a href="eda.html#using-tf-idf"><i class="fa fa-check"></i><b>2.5.2</b> Using TF-IDF</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="eda.html"><a href="eda.html#lexical-divesity-token-type-ratio-ttr"><i class="fa fa-check"></i><b>2.6</b> Lexical Divesity Token Type Ratio TTR</a><ul>
<li class="chapter" data-level="2.6.1" data-path="eda.html"><a href="eda.html#emmanuel-macron-3"><i class="fa fa-check"></i><b>2.6.1</b> Emmanuel Macron</a></li>
<li class="chapter" data-level="2.6.2" data-path="eda.html"><a href="eda.html#boris-johnson-3"><i class="fa fa-check"></i><b>2.6.2</b> Boris Johnson</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="eda.html"><a href="eda.html#zipfs-law"><i class="fa fa-check"></i><b>2.7</b> Zipf’s Law</a><ul>
<li class="chapter" data-level="2.7.1" data-path="eda.html"><a href="eda.html#emmanuel-macron-4"><i class="fa fa-check"></i><b>2.7.1</b> Emmanuel Macron</a></li>
<li class="chapter" data-level="2.7.2" data-path="eda.html"><a href="eda.html#boris-johnson-4"><i class="fa fa-check"></i><b>2.7.2</b> Boris Johnson</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="eda.html"><a href="eda.html#yules-index"><i class="fa fa-check"></i><b>2.8</b> Yule’s index</a><ul>
<li class="chapter" data-level="2.8.1" data-path="eda.html"><a href="eda.html#emmanuel-macron-5"><i class="fa fa-check"></i><b>2.8.1</b> Emmanuel Macron</a></li>
<li class="chapter" data-level="2.8.2" data-path="eda.html"><a href="eda.html#boris-johnson-5"><i class="fa fa-check"></i><b>2.8.2</b> Boris Johnson</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="eda.html"><a href="eda.html#mattr"><i class="fa fa-check"></i><b>2.9</b> MATTR</a><ul>
<li class="chapter" data-level="2.9.1" data-path="eda.html"><a href="eda.html#emmanuel-macron-6"><i class="fa fa-check"></i><b>2.9.1</b> Emmanuel Macron</a></li>
<li class="chapter" data-level="2.9.2" data-path="eda.html"><a href="eda.html#boris-johnson-6"><i class="fa fa-check"></i><b>2.9.2</b> Boris Johnson</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html"><i class="fa fa-check"></i><b>3</b> Sentiment Analysis</a><ul>
<li class="chapter" data-level="3.1" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#analysis-with-the-nrc-library"><i class="fa fa-check"></i><b>3.1</b> Analysis with the “nrc” library</a></li>
<li class="chapter" data-level="3.2" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#analysis-with-the-lsd2015-dictionnary"><i class="fa fa-check"></i><b>3.2</b> Analysis with the LSD2015 dictionnary</a></li>
<li class="chapter" data-level="3.3" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#analysis-with-the-afinn-dictionnary"><i class="fa fa-check"></i><b>3.3</b> Analysis with the “afinn” dictionnary</a><ul>
<li class="chapter" data-level="3.3.1" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#analysis-using-nrc-dictionnary-and-valence-shifters"><i class="fa fa-check"></i><b>3.3.1</b> Analysis using “nrc”&quot; dictionnary and valence shifters</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="similarities.html"><a href="similarities.html"><i class="fa fa-check"></i><b>4</b> Similarities</a><ul>
<li class="chapter" data-level="4.1" data-path="similarities.html"><a href="similarities.html#boris"><i class="fa fa-check"></i><b>4.1</b> Boris</a></li>
<li class="chapter" data-level="4.2" data-path="similarities.html"><a href="similarities.html#macron"><i class="fa fa-check"></i><b>4.2</b> Macron</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="topic-modelling.html"><a href="topic-modelling.html"><i class="fa fa-check"></i><b>5</b> Topic Modelling</a><ul>
<li class="chapter" data-level="5.1" data-path="topic-modelling.html"><a href="topic-modelling.html#boris-johnson-7"><i class="fa fa-check"></i><b>5.1</b> Boris Johnson</a><ul>
<li class="chapter" data-level="5.1.1" data-path="topic-modelling.html"><a href="topic-modelling.html#lsa"><i class="fa fa-check"></i><b>5.1.1</b> LSA</a></li>
<li class="chapter" data-level="5.1.2" data-path="topic-modelling.html"><a href="topic-modelling.html#lda"><i class="fa fa-check"></i><b>5.1.2</b> LDA</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="topic-modelling.html"><a href="topic-modelling.html#macron-1"><i class="fa fa-check"></i><b>5.2</b> Macron</a><ul>
<li class="chapter" data-level="5.2.1" data-path="topic-modelling.html"><a href="topic-modelling.html#lsa-1"><i class="fa fa-check"></i><b>5.2.1</b> LSA</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="topic-modelling.html"><a href="topic-modelling.html#combine"><i class="fa fa-check"></i><b>5.3</b> Combine</a><ul>
<li class="chapter" data-level="5.3.1" data-path="topic-modelling.html"><a href="topic-modelling.html#lsa-2"><i class="fa fa-check"></i><b>5.3.1</b> LSA</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="word-embedding.html"><a href="word-embedding.html"><i class="fa fa-check"></i><b>6</b> Word Embedding</a><ul>
<li class="chapter" data-level="6.1" data-path="word-embedding.html"><a href="word-embedding.html#boris-johnson-8"><i class="fa fa-check"></i><b>6.1</b> Boris Johnson</a></li>
<li class="chapter" data-level="6.2" data-path="word-embedding.html"><a href="word-embedding.html#macron-2"><i class="fa fa-check"></i><b>6.2</b> Macron</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="supervised-learning.html"><a href="supervised-learning.html"><i class="fa fa-check"></i><b>7</b> Supervised learning</a><ul>
<li class="chapter" data-level="7.1" data-path="supervised-learning.html"><a href="supervised-learning.html#lsa-3"><i class="fa fa-check"></i><b>7.1</b> LSA</a></li>
<li class="chapter" data-level="7.2" data-path="supervised-learning.html"><a href="supervised-learning.html#random-forest"><i class="fa fa-check"></i><b>7.2</b> Random forest</a></li>
<li class="chapter" data-level="7.3" data-path="supervised-learning.html"><a href="supervised-learning.html#improving-the-features"><i class="fa fa-check"></i><b>7.3</b> Improving the features</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i><b>8</b> Conclusion</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Dicours Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="supervised-learning" class="section level1">
<h1><span class="header-section-number">Chapter 7</span> Supervised learning</h1>
<p>In this section, we use a supervised learner to develop a classifier of the Politicans’ speeches. The aim of this section is to have a classification model able to correctly attribute a random speech to Boris Johnson or Emmanuel Macron. To do so, we first combine the dataframe of Boris Johnson with the dataframe of Emmanuel Macron. Since those dataframes differ in number of speechs and in length, we divide the speeches into sentences, which would smooth difference between our two dependent outcome possibilities.</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb81-1" data-line-number="1"></a>
<a class="sourceLine" id="cb81-2" data-line-number="2"><span class="co">##Boris Johnson</span></a>
<a class="sourceLine" id="cb81-3" data-line-number="3">boris_<span class="dv">2</span>&lt;-<span class="kw">as_tibble</span>(<span class="kw">c</span>(boris9mars,boris12mars,boris16mars,boris18mars,boris19mars,boris20mars,boris22mars)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb81-4" data-line-number="4"><span class="st">  </span><span class="kw">rename</span>(</a>
<a class="sourceLine" id="cb81-5" data-line-number="5">  <span class="dt">text=</span>value)</a>
<a class="sourceLine" id="cb81-6" data-line-number="6">author=<span class="st">&quot;Boris Johnson&quot;</span></a>
<a class="sourceLine" id="cb81-7" data-line-number="7">boris_supervised&lt;-<span class="st"> </span><span class="kw">cbind</span>(boris_<span class="dv">2</span>, author)</a>
<a class="sourceLine" id="cb81-8" data-line-number="8"></a>
<a class="sourceLine" id="cb81-9" data-line-number="9">boris_<span class="dv">2</span>_sentence&lt;-<span class="kw">get_sentences</span>(boris_supervised)</a>
<a class="sourceLine" id="cb81-10" data-line-number="10"><span class="co">##Emmanuel Macron</span></a>
<a class="sourceLine" id="cb81-11" data-line-number="11">Macron_<span class="dv">2</span>&lt;-<span class="kw">as_tibble</span>(<span class="kw">c</span>(macron12march,macron16march,macron13april)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb81-12" data-line-number="12"><span class="st">  </span><span class="kw">rename</span>(</a>
<a class="sourceLine" id="cb81-13" data-line-number="13">    <span class="dt">text =</span> value)</a>
<a class="sourceLine" id="cb81-14" data-line-number="14"></a>
<a class="sourceLine" id="cb81-15" data-line-number="15">author=<span class="st">&quot;Macron&quot;</span></a>
<a class="sourceLine" id="cb81-16" data-line-number="16">macron_supervised&lt;-<span class="st"> </span><span class="kw">cbind</span>(Macron_<span class="dv">2</span>, author)</a>
<a class="sourceLine" id="cb81-17" data-line-number="17"></a>
<a class="sourceLine" id="cb81-18" data-line-number="18">macron_<span class="dv">2</span>_sentence&lt;-<span class="kw">get_sentences</span>(macron_supervised)</a>
<a class="sourceLine" id="cb81-19" data-line-number="19"></a>
<a class="sourceLine" id="cb81-20" data-line-number="20"><span class="co">##Combine the 2 dataframes</span></a>
<a class="sourceLine" id="cb81-21" data-line-number="21">combine &lt;-<span class="st"> </span><span class="kw">rbind</span>(boris_<span class="dv">2</span>_sentence, macron_<span class="dv">2</span>_sentence)</a>
<a class="sourceLine" id="cb81-22" data-line-number="22"></a>
<a class="sourceLine" id="cb81-23" data-line-number="23"></a>
<a class="sourceLine" id="cb81-24" data-line-number="24"><span class="co">## Tokenization</span></a>
<a class="sourceLine" id="cb81-25" data-line-number="25">combine_corpus&lt;-<span class="kw">corpus</span>(combine)</a>
<a class="sourceLine" id="cb81-26" data-line-number="26">combine_tokens&lt;-<span class="st"> </span><span class="kw">tokens</span>(combine_corpus, <span class="dt">remove_numbers =</span> <span class="ot">TRUE</span>, <span class="dt">remove_punct =</span> <span class="ot">TRUE</span>, <span class="dt">remove_symbols =</span> <span class="ot">TRUE</span>, <span class="dt">remove_separators =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb81-27" data-line-number="27"></a>
<a class="sourceLine" id="cb81-28" data-line-number="28"><span class="co">##combi Lemmatization</span></a>
<a class="sourceLine" id="cb81-29" data-line-number="29"></a>
<a class="sourceLine" id="cb81-30" data-line-number="30"></a>
<a class="sourceLine" id="cb81-31" data-line-number="31">combine_tokens &lt;-<span class="st"> </span><span class="kw">tokens_replace</span>(combine_tokens, <span class="dt">pattern=</span>hash_lemmas<span class="op">$</span>token, <span class="dt">replacement =</span> hash_lemmas<span class="op">$</span>lemma)</a>
<a class="sourceLine" id="cb81-32" data-line-number="32"></a>
<a class="sourceLine" id="cb81-33" data-line-number="33"></a>
<a class="sourceLine" id="cb81-34" data-line-number="34"><span class="co">## Cleaning</span></a>
<a class="sourceLine" id="cb81-35" data-line-number="35">combine_tokens =<span class="st"> </span>combine_tokens <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb81-36" data-line-number="36"><span class="st">  </span><span class="kw">tokens_tolower</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb81-37" data-line-number="37"><span class="st">  </span><span class="kw">tokens_remove</span>(<span class="kw">stopwords</span>(<span class="st">&quot;english&quot;</span>))</a>
<a class="sourceLine" id="cb81-38" data-line-number="38"></a>
<a class="sourceLine" id="cb81-39" data-line-number="39">y&lt;-<span class="kw">factor</span>(<span class="kw">docvars</span>(combine_tokens,<span class="st">&quot;author&quot;</span>))</a></code></pre></div>
<p>Then, we build the featues. To this aim, we first compute the DTM matrix.</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb82-1" data-line-number="1">combine.dfm&lt;-<span class="kw">dfm</span>(combine_tokens)</a>
<a class="sourceLine" id="cb82-2" data-line-number="2">combine.dfm</a>
<a class="sourceLine" id="cb82-3" data-line-number="3"><span class="co">#&gt; Document-feature matrix of: 771 documents, 1,691 features (99.4% sparse) and 3 docvars.</span></a>
<a class="sourceLine" id="cb82-4" data-line-number="4"><span class="co">#&gt;        features</span></a>
<a class="sourceLine" id="cb82-5" data-line-number="5"><span class="co">#&gt; docs    morning meeting government&#39;s cobr emergency committee</span></a>
<a class="sourceLine" id="cb82-6" data-line-number="6"><span class="co">#&gt;   text1       0       0            0    0         0         0</span></a>
<a class="sourceLine" id="cb82-7" data-line-number="7"><span class="co">#&gt;   text2       1       0            1    1         1         1</span></a>
<a class="sourceLine" id="cb82-8" data-line-number="8"><span class="co">#&gt;   text3       0       0            0    0         0         0</span></a>
<a class="sourceLine" id="cb82-9" data-line-number="9"><span class="co">#&gt;   text4       0       0            0    0         0         0</span></a>
<a class="sourceLine" id="cb82-10" data-line-number="10"><span class="co">#&gt;   text5       0       0            0    0         0         0</span></a>
<a class="sourceLine" id="cb82-11" data-line-number="11"><span class="co">#&gt;   text6       0       0            0    0         0         0</span></a>
<a class="sourceLine" id="cb82-12" data-line-number="12"><span class="co">#&gt;        features</span></a>
<a class="sourceLine" id="cb82-13" data-line-number="13"><span class="co">#&gt; docs    coronavirus outbreak first scotland</span></a>
<a class="sourceLine" id="cb82-14" data-line-number="14"><span class="co">#&gt;   text1           0        0     0        0</span></a>
<a class="sourceLine" id="cb82-15" data-line-number="15"><span class="co">#&gt;   text2           1        1     0        0</span></a>
<a class="sourceLine" id="cb82-16" data-line-number="16"><span class="co">#&gt;   text3           0        0     3        1</span></a>
<a class="sourceLine" id="cb82-17" data-line-number="17"><span class="co">#&gt;   text4           0        0     0        0</span></a>
<a class="sourceLine" id="cb82-18" data-line-number="18"><span class="co">#&gt;   text5           0        0     0        0</span></a>
<a class="sourceLine" id="cb82-19" data-line-number="19"><span class="co">#&gt;   text6           1        0     0        0</span></a>
<a class="sourceLine" id="cb82-20" data-line-number="20"><span class="co">#&gt; [ reached max_ndoc ... 765 more documents, reached max_nfeat ... 1,681 more features ]</span></a></code></pre></div>
<div id="lsa-3" class="section level2">
<h2><span class="header-section-number">7.1</span> LSA</h2>
<p>Because of the huge number of tokens, the feature matrix obtained may be too big to train a model in a reasonable amount of time. We thus apply a reduction dimension technque in order to obtain less features while keeping the relevant information. LSA is the perfect technique to achieve this. We target 30 dimensions (30 subjects)</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb83-1" data-line-number="1"></a>
<a class="sourceLine" id="cb83-2" data-line-number="2">combine_corpus.dfm &lt;-<span class="st"> </span><span class="kw">dfm</span>(combine_corpus)</a>
<a class="sourceLine" id="cb83-3" data-line-number="3">cmod&lt;-<span class="kw">textmodel_lsa</span>(combine_corpus.dfm,<span class="dt">nd=</span><span class="dv">30</span>)</a></code></pre></div>
</div>
<div id="random-forest" class="section level2">
<h2><span class="header-section-number">7.2</span> Random forest</h2>
<p>After preparing our data to be used by the learner, we decide to run a random forest, which is a robust method to find the best classification model by computing a large set of classification tree to obtain the most pertinent values of classification criterias.
After building our model, we create a training and a test sets. In this simple context, in order to illustrate the concepts without too long computation times, we will limit ourselves to just one training set and one test set by applying the Pareto law 80-20.</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb84-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">782</span>)</a>
<a class="sourceLine" id="cb84-2" data-line-number="2">df&lt;-<span class="kw">data.frame</span>(<span class="dt">Class=</span>y, <span class="dt">x=</span>cmod<span class="op">$</span>docs)</a>
<a class="sourceLine" id="cb84-3" data-line-number="3">index.tr&lt;-<span class="kw">sample</span>(<span class="dt">size =</span> <span class="kw">round</span>(<span class="fl">0.8</span><span class="op">*</span><span class="kw">length</span>(y)),<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(y)),<span class="dt">replace =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb84-4" data-line-number="4"></a>
<a class="sourceLine" id="cb84-5" data-line-number="5">df.tr&lt;-df[index.tr,]</a>
<a class="sourceLine" id="cb84-6" data-line-number="6">df.te&lt;-df[<span class="op">-</span>index.tr,]</a>
<a class="sourceLine" id="cb84-7" data-line-number="7"></a>
<a class="sourceLine" id="cb84-8" data-line-number="8"></a>
<a class="sourceLine" id="cb84-9" data-line-number="9">combine.fit&lt;-<span class="kw">ranger</span>(Class<span class="op">~</span>.,</a>
<a class="sourceLine" id="cb84-10" data-line-number="10">                    <span class="dt">data =</span> df.tr)</a>
<a class="sourceLine" id="cb84-11" data-line-number="11">pred.te&lt;-<span class="kw">predict</span>(combine.fit,df.te)</a></code></pre></div>
<p>In order to see the prediction quality of the model, we call the confusionMatrix function in the caret package:</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb85-1" data-line-number="1"></a>
<a class="sourceLine" id="cb85-2" data-line-number="2">confusionMatrix&lt;-<span class="kw">confusionMatrix</span>(<span class="dt">data=</span>pred.te<span class="op">$</span>predictions,<span class="dt">reference =</span> df.te<span class="op">$</span>Class)</a>
<a class="sourceLine" id="cb85-3" data-line-number="3">confusionMatrix</a>
<a class="sourceLine" id="cb85-4" data-line-number="4"><span class="co">#&gt; Confusion Matrix and Statistics</span></a>
<a class="sourceLine" id="cb85-5" data-line-number="5"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb85-6" data-line-number="6"><span class="co">#&gt;                Reference</span></a>
<a class="sourceLine" id="cb85-7" data-line-number="7"><span class="co">#&gt; Prediction      Boris Johnson Macron</span></a>
<a class="sourceLine" id="cb85-8" data-line-number="8"><span class="co">#&gt;   Boris Johnson            23      6</span></a>
<a class="sourceLine" id="cb85-9" data-line-number="9"><span class="co">#&gt;   Macron                   29     96</span></a>
<a class="sourceLine" id="cb85-10" data-line-number="10"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb85-11" data-line-number="11"><span class="co">#&gt;                Accuracy : 0.773         </span></a>
<a class="sourceLine" id="cb85-12" data-line-number="12"><span class="co">#&gt;                  95% CI : (0.698, 0.836)</span></a>
<a class="sourceLine" id="cb85-13" data-line-number="13"><span class="co">#&gt;     No Information Rate : 0.662         </span></a>
<a class="sourceLine" id="cb85-14" data-line-number="14"><span class="co">#&gt;     P-Value [Acc &gt; NIR] : 0.00191       </span></a>
<a class="sourceLine" id="cb85-15" data-line-number="15"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb85-16" data-line-number="16"><span class="co">#&gt;                   Kappa : 0.43          </span></a>
<a class="sourceLine" id="cb85-17" data-line-number="17"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb85-18" data-line-number="18"><span class="co">#&gt;  Mcnemar&#39;s Test P-Value : 0.00020       </span></a>
<a class="sourceLine" id="cb85-19" data-line-number="19"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb85-20" data-line-number="20"><span class="co">#&gt;             Sensitivity : 0.442         </span></a>
<a class="sourceLine" id="cb85-21" data-line-number="21"><span class="co">#&gt;             Specificity : 0.941         </span></a>
<a class="sourceLine" id="cb85-22" data-line-number="22"><span class="co">#&gt;          Pos Pred Value : 0.793         </span></a>
<a class="sourceLine" id="cb85-23" data-line-number="23"><span class="co">#&gt;          Neg Pred Value : 0.768         </span></a>
<a class="sourceLine" id="cb85-24" data-line-number="24"><span class="co">#&gt;              Prevalence : 0.338         </span></a>
<a class="sourceLine" id="cb85-25" data-line-number="25"><span class="co">#&gt;          Detection Rate : 0.149         </span></a>
<a class="sourceLine" id="cb85-26" data-line-number="26"><span class="co">#&gt;    Detection Prevalence : 0.188         </span></a>
<a class="sourceLine" id="cb85-27" data-line-number="27"><span class="co">#&gt;       Balanced Accuracy : 0.692         </span></a>
<a class="sourceLine" id="cb85-28" data-line-number="28"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb85-29" data-line-number="29"><span class="co">#&gt;        &#39;Positive&#39; Class : Boris Johnson </span></a>
<a class="sourceLine" id="cb85-30" data-line-number="30"><span class="co">#&gt; </span></a></code></pre></div>
<p>The model has an accuracy of 77.3%, is is a quite poor accuracy, but enough good for a first try.
But… if we have a look one the sensitivity ( which is the % of predict the positive class, here this is Boris johnson) it is only 44.2%.
So, we have a good model in order to predict the speech of Macon, about 94%, but much less to predict Boris Johnson.</p>
</div>
<div id="improving-the-features" class="section level2">
<h2><span class="header-section-number">7.3</span> Improving the features</h2>
<p>In order to improve the accuracy, we look to improve the features construction. We may consider the elements fo feature construction as hyperparameters to be optimized. Therefore we compare differents dimensions with their corresponding accuracy. In the figure <a href="supervised-learning.html#fig:accuracy">7.1</a>, we notice that with a dimension of 100, the accuracy will get higher than 84% !</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb86-1" data-line-number="1">nd.vec&lt;-<span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">5</span>,<span class="dv">25</span>,<span class="dv">50</span>,<span class="dv">100</span>,<span class="dv">500</span>,<span class="dv">1000</span>)</a>
<a class="sourceLine" id="cb86-2" data-line-number="2">acc.vec&lt;-<span class="kw">numeric</span>(<span class="kw">length</span>(nd.vec))</a>
<a class="sourceLine" id="cb86-3" data-line-number="3"><span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(nd.vec)) {</a>
<a class="sourceLine" id="cb86-4" data-line-number="4">  cmod&lt;-<span class="kw">textmodel_lsa</span>(combine_corpus.dfm,<span class="dt">nd=</span>nd.vec[j])</a>
<a class="sourceLine" id="cb86-5" data-line-number="5">  df&lt;-<span class="kw">data.frame</span>(<span class="dt">class=</span>y,<span class="dt">x=</span>cmod<span class="op">$</span>docs)</a>
<a class="sourceLine" id="cb86-6" data-line-number="6">  df.tr&lt;-df[index.tr,]</a>
<a class="sourceLine" id="cb86-7" data-line-number="7">  df.te&lt;-df[<span class="op">-</span>index.tr,]</a>
<a class="sourceLine" id="cb86-8" data-line-number="8">  </a>
<a class="sourceLine" id="cb86-9" data-line-number="9">  combine.fit&lt;-<span class="kw">ranger</span>(class<span class="op">~</span>.,</a>
<a class="sourceLine" id="cb86-10" data-line-number="10">                    <span class="dt">data =</span> df.tr)</a>
<a class="sourceLine" id="cb86-11" data-line-number="11">pred.te&lt;-<span class="kw">predict</span>(combine.fit,df.te)</a>
<a class="sourceLine" id="cb86-12" data-line-number="12">acc.vec[j]&lt;-<span class="kw">confusionMatrix</span>(<span class="dt">data=</span>pred.te<span class="op">$</span>predictions,<span class="dt">reference =</span> df.te<span class="op">$</span>class)<span class="op">$</span>overall[<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb86-13" data-line-number="13">  </a>
<a class="sourceLine" id="cb86-14" data-line-number="14">}</a>
<a class="sourceLine" id="cb86-15" data-line-number="15">acc.vec</a>
<a class="sourceLine" id="cb86-16" data-line-number="16"><span class="co">#&gt; [1] 0.740 0.779 0.779 0.805 0.786 0.727 0.708</span></a>
<a class="sourceLine" id="cb86-17" data-line-number="17"></a>
<a class="sourceLine" id="cb86-18" data-line-number="18"><span class="kw">plot</span>(acc.vec<span class="op">~</span>nd.vec,<span class="dt">type=</span><span class="st">&quot;b&quot;</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:accuracy"></span>
<img src="Text-Mining_files/figure-html/accuracy-1.png" alt="Accuracy" width="70%" />
<p class="caption">
Figure 7.1: Accuracy
</p>
</div>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb87-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">788</span>)</a>
<a class="sourceLine" id="cb87-2" data-line-number="2">combine_corpus.dfm &lt;-<span class="st"> </span><span class="kw">dfm</span>(combine_corpus)</a>
<a class="sourceLine" id="cb87-3" data-line-number="3">cmod&lt;-<span class="kw">textmodel_lsa</span>(combine_corpus.dfm,<span class="dt">nd=</span><span class="dv">100</span>)</a>
<a class="sourceLine" id="cb87-4" data-line-number="4"></a>
<a class="sourceLine" id="cb87-5" data-line-number="5">df&lt;-<span class="kw">data.frame</span>(<span class="dt">class=</span>y, <span class="dt">x=</span>cmod<span class="op">$</span>docs)</a>
<a class="sourceLine" id="cb87-6" data-line-number="6">index.tr&lt;-<span class="kw">sample</span>(<span class="dt">size =</span> <span class="kw">round</span>(<span class="fl">0.8</span><span class="op">*</span><span class="kw">length</span>(y)),<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(y)),<span class="dt">replace =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb87-7" data-line-number="7"></a>
<a class="sourceLine" id="cb87-8" data-line-number="8">df.tr&lt;-df[index.tr,]</a>
<a class="sourceLine" id="cb87-9" data-line-number="9">df.te&lt;-df[<span class="op">-</span>index.tr,]</a>
<a class="sourceLine" id="cb87-10" data-line-number="10"></a>
<a class="sourceLine" id="cb87-11" data-line-number="11"></a>
<a class="sourceLine" id="cb87-12" data-line-number="12">combine.fit&lt;-<span class="kw">ranger</span>(class<span class="op">~</span>.,</a>
<a class="sourceLine" id="cb87-13" data-line-number="13">                    <span class="dt">data =</span> df.tr)</a>
<a class="sourceLine" id="cb87-14" data-line-number="14">pred.te&lt;-<span class="kw">predict</span>(combine.fit,df.te)</a>
<a class="sourceLine" id="cb87-15" data-line-number="15"></a>
<a class="sourceLine" id="cb87-16" data-line-number="16">confusionmatrix_<span class="dv">2</span>&lt;-<span class="kw">confusionMatrix</span>(<span class="dt">data=</span>pred.te<span class="op">$</span>predictions,<span class="dt">reference =</span> df.te<span class="op">$</span>class)</a>
<a class="sourceLine" id="cb87-17" data-line-number="17">confusionmatrix_<span class="dv">2</span></a>
<a class="sourceLine" id="cb87-18" data-line-number="18"><span class="co">#&gt; Confusion Matrix and Statistics</span></a>
<a class="sourceLine" id="cb87-19" data-line-number="19"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb87-20" data-line-number="20"><span class="co">#&gt;                Reference</span></a>
<a class="sourceLine" id="cb87-21" data-line-number="21"><span class="co">#&gt; Prediction      Boris Johnson Macron</span></a>
<a class="sourceLine" id="cb87-22" data-line-number="22"><span class="co">#&gt;   Boris Johnson            32      4</span></a>
<a class="sourceLine" id="cb87-23" data-line-number="23"><span class="co">#&gt;   Macron                   19     99</span></a>
<a class="sourceLine" id="cb87-24" data-line-number="24"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb87-25" data-line-number="25"><span class="co">#&gt;                Accuracy : 0.851         </span></a>
<a class="sourceLine" id="cb87-26" data-line-number="26"><span class="co">#&gt;                  95% CI : (0.784, 0.903)</span></a>
<a class="sourceLine" id="cb87-27" data-line-number="27"><span class="co">#&gt;     No Information Rate : 0.669         </span></a>
<a class="sourceLine" id="cb87-28" data-line-number="28"><span class="co">#&gt;     P-Value [Acc &gt; NIR] : 2.57e-07      </span></a>
<a class="sourceLine" id="cb87-29" data-line-number="29"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb87-30" data-line-number="30"><span class="co">#&gt;                   Kappa : 0.636         </span></a>
<a class="sourceLine" id="cb87-31" data-line-number="31"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb87-32" data-line-number="32"><span class="co">#&gt;  Mcnemar&#39;s Test P-Value : 0.00351       </span></a>
<a class="sourceLine" id="cb87-33" data-line-number="33"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb87-34" data-line-number="34"><span class="co">#&gt;             Sensitivity : 0.627         </span></a>
<a class="sourceLine" id="cb87-35" data-line-number="35"><span class="co">#&gt;             Specificity : 0.961         </span></a>
<a class="sourceLine" id="cb87-36" data-line-number="36"><span class="co">#&gt;          Pos Pred Value : 0.889         </span></a>
<a class="sourceLine" id="cb87-37" data-line-number="37"><span class="co">#&gt;          Neg Pred Value : 0.839         </span></a>
<a class="sourceLine" id="cb87-38" data-line-number="38"><span class="co">#&gt;              Prevalence : 0.331         </span></a>
<a class="sourceLine" id="cb87-39" data-line-number="39"><span class="co">#&gt;          Detection Rate : 0.208         </span></a>
<a class="sourceLine" id="cb87-40" data-line-number="40"><span class="co">#&gt;    Detection Prevalence : 0.234         </span></a>
<a class="sourceLine" id="cb87-41" data-line-number="41"><span class="co">#&gt;       Balanced Accuracy : 0.794         </span></a>
<a class="sourceLine" id="cb87-42" data-line-number="42"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb87-43" data-line-number="43"><span class="co">#&gt;        &#39;Positive&#39; Class : Boris Johnson </span></a>
<a class="sourceLine" id="cb87-44" data-line-number="44"><span class="co">#&gt; </span></a></code></pre></div>
<p>By re-running the same model but by increasing dimensions rather than weighting the sentences, we observe an increase in accuracy,now the accuracy is 85.1%. Sensitivity has improved by 18.50% but the learner has a still a poor prediction ability, in spite of the increase of the dimensions.The improvement by weighting the independent variables would be potentially more efficient. We would keep it as being part of further investigations.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="word-embedding.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="conclusion.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
