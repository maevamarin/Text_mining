<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Word Embedding | Dicours Analysis</title>
  <meta name="description" content="Chapter 6 Word Embedding | Dicours Analysis" />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Word Embedding | Dicours Analysis" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Word Embedding | Dicours Analysis" />
  
  
  

<meta name="author" content="Eugénie Mathieu, Maeva Marin, Hadrien Renger, Wajma Nazim" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="topic-modelling.html"/>
<link rel="next" href="supervised-learning.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.15/datatables.js"></script>
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#overview-and-motivation"><i class="fa fa-check"></i><b>1.1</b> Overview and Motivation</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="eda.html"><a href="eda.html"><i class="fa fa-check"></i><b>2</b> EDA</a><ul>
<li class="chapter" data-level="2.1" data-path="eda.html"><a href="eda.html#data-acquisition"><i class="fa fa-check"></i><b>2.1</b> Data Acquisition</a><ul>
<li class="chapter" data-level="2.1.1" data-path="eda.html"><a href="eda.html#emmanuel-macron"><i class="fa fa-check"></i><b>2.1.1</b> Emmanuel Macron</a></li>
<li class="chapter" data-level="2.1.2" data-path="eda.html"><a href="eda.html#boris-johnson"><i class="fa fa-check"></i><b>2.1.2</b> Boris Johnson</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="eda.html"><a href="eda.html#tokenisation-lemmatization-cleaning"><i class="fa fa-check"></i><b>2.2</b> Tokenisation, Lemmatization &amp; Cleaning</a><ul>
<li class="chapter" data-level="2.2.1" data-path="eda.html"><a href="eda.html#emmanuel-macron-1"><i class="fa fa-check"></i><b>2.2.1</b> Emmanuel Macron</a></li>
<li class="chapter" data-level="2.2.2" data-path="eda.html"><a href="eda.html#boris-johnson-1"><i class="fa fa-check"></i><b>2.2.2</b> Boris Johnson</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="eda.html"><a href="eda.html#document-term-matrix-dtm"><i class="fa fa-check"></i><b>2.3</b> Document-Term Matrix DTM</a><ul>
<li class="chapter" data-level="2.3.1" data-path="eda.html"><a href="eda.html#table"><i class="fa fa-check"></i><b>2.3.1</b> Table</a></li>
<li class="chapter" data-level="2.3.2" data-path="eda.html"><a href="eda.html#most-frequent-words"><i class="fa fa-check"></i><b>2.3.2</b> Most frequent words</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="eda.html"><a href="eda.html#tf-idf"><i class="fa fa-check"></i><b>2.4</b> TF-IDF</a><ul>
<li class="chapter" data-level="2.4.1" data-path="eda.html"><a href="eda.html#emmanuel-macron-2"><i class="fa fa-check"></i><b>2.4.1</b> Emmanuel Macron</a></li>
<li class="chapter" data-level="2.4.2" data-path="eda.html"><a href="eda.html#boris-johnson-2"><i class="fa fa-check"></i><b>2.4.2</b> Boris Johnson</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="eda.html"><a href="eda.html#cloud-of-words"><i class="fa fa-check"></i><b>2.5</b> Cloud of Words</a><ul>
<li class="chapter" data-level="2.5.1" data-path="eda.html"><a href="eda.html#usind-dfm"><i class="fa fa-check"></i><b>2.5.1</b> Usind DFM</a></li>
<li class="chapter" data-level="2.5.2" data-path="eda.html"><a href="eda.html#using-tf-idf"><i class="fa fa-check"></i><b>2.5.2</b> Using TF-IDF</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="eda.html"><a href="eda.html#lexical-divesity-token-type-ratio-ttr"><i class="fa fa-check"></i><b>2.6</b> Lexical Divesity Token Type Ratio TTR</a><ul>
<li class="chapter" data-level="2.6.1" data-path="eda.html"><a href="eda.html#emmanuel-macron-3"><i class="fa fa-check"></i><b>2.6.1</b> Emmanuel Macron</a></li>
<li class="chapter" data-level="2.6.2" data-path="eda.html"><a href="eda.html#boris-johnson-3"><i class="fa fa-check"></i><b>2.6.2</b> Boris Johnson</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="eda.html"><a href="eda.html#zipfs-law"><i class="fa fa-check"></i><b>2.7</b> Zipf’s Law</a><ul>
<li class="chapter" data-level="2.7.1" data-path="eda.html"><a href="eda.html#emmanuel-macron-4"><i class="fa fa-check"></i><b>2.7.1</b> Emmanuel Macron</a></li>
<li class="chapter" data-level="2.7.2" data-path="eda.html"><a href="eda.html#boris-johnson-4"><i class="fa fa-check"></i><b>2.7.2</b> Boris Johnson</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="eda.html"><a href="eda.html#yules-index"><i class="fa fa-check"></i><b>2.8</b> Yule’s index</a><ul>
<li class="chapter" data-level="2.8.1" data-path="eda.html"><a href="eda.html#emmanuel-macron-5"><i class="fa fa-check"></i><b>2.8.1</b> Emmanuel Macron</a></li>
<li class="chapter" data-level="2.8.2" data-path="eda.html"><a href="eda.html#boris-johnson-5"><i class="fa fa-check"></i><b>2.8.2</b> Boris Johnson</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="eda.html"><a href="eda.html#mattr"><i class="fa fa-check"></i><b>2.9</b> MATTR</a><ul>
<li class="chapter" data-level="2.9.1" data-path="eda.html"><a href="eda.html#emmanuel-macron-6"><i class="fa fa-check"></i><b>2.9.1</b> Emmanuel Macron</a></li>
<li class="chapter" data-level="2.9.2" data-path="eda.html"><a href="eda.html#boris-johnson-6"><i class="fa fa-check"></i><b>2.9.2</b> Boris Johnson</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html"><i class="fa fa-check"></i><b>3</b> Sentiment Analysis</a><ul>
<li class="chapter" data-level="3.1" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#analysis-with-the-nrc-library"><i class="fa fa-check"></i><b>3.1</b> Analysis with the “nrc” library</a></li>
<li class="chapter" data-level="3.2" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#analysis-with-the-lsd2015-dictionnary"><i class="fa fa-check"></i><b>3.2</b> Analysis with the LSD2015 dictionnary</a></li>
<li class="chapter" data-level="3.3" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#analysis-with-the-afinn-dictionnary"><i class="fa fa-check"></i><b>3.3</b> Analysis with the “afinn” dictionnary</a><ul>
<li class="chapter" data-level="3.3.1" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#analysis-using-nrc-dictionnary-and-valence-shifters"><i class="fa fa-check"></i><b>3.3.1</b> Analysis using “nrc”&quot; dictionnary and valence shifters</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="similarities.html"><a href="similarities.html"><i class="fa fa-check"></i><b>4</b> Similarities</a><ul>
<li class="chapter" data-level="4.1" data-path="similarities.html"><a href="similarities.html#boris"><i class="fa fa-check"></i><b>4.1</b> Boris</a></li>
<li class="chapter" data-level="4.2" data-path="similarities.html"><a href="similarities.html#macron"><i class="fa fa-check"></i><b>4.2</b> Macron</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="topic-modelling.html"><a href="topic-modelling.html"><i class="fa fa-check"></i><b>5</b> Topic Modelling</a><ul>
<li class="chapter" data-level="5.1" data-path="topic-modelling.html"><a href="topic-modelling.html#boris-johnson-7"><i class="fa fa-check"></i><b>5.1</b> Boris Johnson</a><ul>
<li class="chapter" data-level="5.1.1" data-path="topic-modelling.html"><a href="topic-modelling.html#lsa"><i class="fa fa-check"></i><b>5.1.1</b> LSA</a></li>
<li class="chapter" data-level="5.1.2" data-path="topic-modelling.html"><a href="topic-modelling.html#lda"><i class="fa fa-check"></i><b>5.1.2</b> LDA</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="topic-modelling.html"><a href="topic-modelling.html#macron-1"><i class="fa fa-check"></i><b>5.2</b> Macron</a><ul>
<li class="chapter" data-level="5.2.1" data-path="topic-modelling.html"><a href="topic-modelling.html#lsa-1"><i class="fa fa-check"></i><b>5.2.1</b> LSA</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="topic-modelling.html"><a href="topic-modelling.html#combine"><i class="fa fa-check"></i><b>5.3</b> Combine</a><ul>
<li class="chapter" data-level="5.3.1" data-path="topic-modelling.html"><a href="topic-modelling.html#lsa-2"><i class="fa fa-check"></i><b>5.3.1</b> LSA</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="word-embedding.html"><a href="word-embedding.html"><i class="fa fa-check"></i><b>6</b> Word Embedding</a><ul>
<li class="chapter" data-level="6.1" data-path="word-embedding.html"><a href="word-embedding.html#boris-johnson-8"><i class="fa fa-check"></i><b>6.1</b> Boris Johnson</a></li>
<li class="chapter" data-level="6.2" data-path="word-embedding.html"><a href="word-embedding.html#macron-2"><i class="fa fa-check"></i><b>6.2</b> Macron</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="supervised-learning.html"><a href="supervised-learning.html"><i class="fa fa-check"></i><b>7</b> Supervised learning</a><ul>
<li class="chapter" data-level="7.1" data-path="supervised-learning.html"><a href="supervised-learning.html#lsa-3"><i class="fa fa-check"></i><b>7.1</b> LSA</a></li>
<li class="chapter" data-level="7.2" data-path="supervised-learning.html"><a href="supervised-learning.html#random-forest"><i class="fa fa-check"></i><b>7.2</b> Random forest</a></li>
<li class="chapter" data-level="7.3" data-path="supervised-learning.html"><a href="supervised-learning.html#improving-the-features"><i class="fa fa-check"></i><b>7.3</b> Improving the features</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i><b>8</b> Conclusion</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Dicours Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="word-embedding" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Word Embedding</h1>
<p>A word embedding is a learned representation for text where words that have the same meaning have a similar representation.
This is a method of learning a representation of words used in particular in automatic language processing. The term should rather be rendered by vectorisation of words in order to correspond more neatly to this method.</p>
<div id="boris-johnson-8" class="section level2">
<h2><span class="header-section-number">6.1</span> Boris Johnson</h2>
<p>Here, we compute the co-occurence matrix. We use the fcm function from quanteda. We use a window lenght 5.</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb71-1" data-line-number="1">speech.coo.boris&lt;-<span class="kw">fcm</span>(corpus_boris,<span class="dt">context=</span><span class="st">&quot;window&quot;</span>,<span class="dt">window=</span><span class="dv">5</span>, <span class="dt">tri=</span><span class="ot">FALSE</span>)</a></code></pre></div>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb72-1" data-line-number="1">p&lt;-<span class="dv">2</span> <span class="co">#word embedding dimension</span></a>
<a class="sourceLine" id="cb72-2" data-line-number="2">speech.glove.boris&lt;-GlobalVectors<span class="op">$</span><span class="kw">new</span>(<span class="dt">rank =</span> p,<span class="dt">x_max =</span> <span class="dv">10</span>) <span class="co">#xmas is a neede technical option</span></a>
<a class="sourceLine" id="cb72-3" data-line-number="3">speech.weC.boris&lt;-speech.glove.boris<span class="op">$</span><span class="kw">fit_transform</span>(speech.coo.boris)</a>
<a class="sourceLine" id="cb72-4" data-line-number="4"><span class="co">#&gt; INFO  [12:20:26.253] epoch 1, loss 0.0342 </span></a>
<a class="sourceLine" id="cb72-5" data-line-number="5"><span class="co">#&gt; INFO  [12:20:26.268] epoch 2, loss 0.0244 </span></a>
<a class="sourceLine" id="cb72-6" data-line-number="6"><span class="co">#&gt; INFO  [12:20:26.277] epoch 3, loss 0.0225 </span></a>
<a class="sourceLine" id="cb72-7" data-line-number="7"><span class="co">#&gt; INFO  [12:20:26.283] epoch 4, loss 0.0215 </span></a>
<a class="sourceLine" id="cb72-8" data-line-number="8"><span class="co">#&gt; INFO  [12:20:26.289] epoch 5, loss 0.0208 </span></a>
<a class="sourceLine" id="cb72-9" data-line-number="9"><span class="co">#&gt; INFO  [12:20:26.295] epoch 6, loss 0.0203 </span></a>
<a class="sourceLine" id="cb72-10" data-line-number="10"><span class="co">#&gt; INFO  [12:20:26.301] epoch 7, loss 0.0198 </span></a>
<a class="sourceLine" id="cb72-11" data-line-number="11"><span class="co">#&gt; INFO  [12:20:26.306] epoch 8, loss 0.0193 </span></a>
<a class="sourceLine" id="cb72-12" data-line-number="12"><span class="co">#&gt; INFO  [12:20:26.312] epoch 9, loss 0.0189 </span></a>
<a class="sourceLine" id="cb72-13" data-line-number="13"><span class="co">#&gt; INFO  [12:20:26.318] epoch 10, loss 0.0184</span></a></code></pre></div>
<p>For illustration purpose, we now plot the 50 most used terms as you can observe in the figure <a href="word-embedding.html#fig:speech-we">6.1</a>.
More the words are close, more they are similar. Two word are similar if they are often use in the same context.</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb73-1" data-line-number="1">n.w.boris&lt;-<span class="kw">apply</span>(corpus_boris.dfm,<span class="dv">2</span>,sum) <span class="co">#compute the number of times each term is used</span></a>
<a class="sourceLine" id="cb73-2" data-line-number="2">index&lt;-<span class="kw">order</span>(n.w.boris,<span class="dt">decreasing =</span> <span class="ot">TRUE</span>)[<span class="dv">1</span><span class="op">:</span><span class="dv">50</span>]</a>
<a class="sourceLine" id="cb73-3" data-line-number="3"><span class="kw">plot</span>(speech.weC.boris[index,],<span class="dt">type =</span> <span class="st">&quot;n&quot;</span>,<span class="dt">xlab =</span> <span class="st">&quot;Dimension 1&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Dimendion 2&quot;</span>)</a>
<a class="sourceLine" id="cb73-4" data-line-number="4"><span class="kw">text</span>(<span class="dt">x=</span>speech.weC.boris[index,],<span class="dt">labels =</span> <span class="kw">rownames</span>(speech.weC.boris[index,]))</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:speech-we"></span>
<img src="Text-Mining_files/figure-html/speech-we-1.png" alt="The 50 most used terms" width="70%" />
<p class="caption">
Figure 6.1: The 50 most used terms
</p>
</div>
<p>In the figure <a href="word-embedding.html#fig:dendogram-boris">6.2</a></p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb74-1" data-line-number="1">speech.dtm &lt;-corpus_boris.dfm</a>
<a class="sourceLine" id="cb74-2" data-line-number="2">speech.rwmd.model.boris&lt;-RelaxedWordMoversDistance<span class="op">$</span><span class="kw">new</span>(corpus_boris.dfm,speech.weC.boris)</a>
<a class="sourceLine" id="cb74-3" data-line-number="3">speech.rwms.boris&lt;-speech.rwmd.model.boris<span class="op">$</span><span class="kw">sim2</span>(corpus_boris.dfm)</a>
<a class="sourceLine" id="cb74-4" data-line-number="4">speech.rwmd.boris&lt;-speech.rwmd.model.boris<span class="op">$</span><span class="kw">dist2</span>(corpus_boris.dfm)</a>
<a class="sourceLine" id="cb74-5" data-line-number="5"></a>
<a class="sourceLine" id="cb74-6" data-line-number="6">speech.hc.boris&lt;-<span class="kw">hclust</span>(<span class="kw">as.dist</span>(speech.rwmd.boris))</a>
<a class="sourceLine" id="cb74-7" data-line-number="7"><span class="kw">plot</span>(speech.hc.boris,<span class="dt">cex=</span><span class="fl">0.8</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:dendogram-boris"></span>
<img src="Text-Mining_files/figure-html/dendogram-boris-1.png" alt="Cluster Dendogram" width="70%" />
<p class="caption">
Figure 6.2: Cluster Dendogram
</p>
</div>
<p>We can observe that there is some coherence within the groups in terms the date of the speech.</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb75-1" data-line-number="1">speech.cl.boris&lt;-<span class="st"> </span><span class="kw">cutree</span>(speech.hc.boris,<span class="dt">k=</span><span class="dv">4</span>)</a>
<a class="sourceLine" id="cb75-2" data-line-number="2">corpus_boris.dfm[speech.cl.boris<span class="op">==</span><span class="dv">1</span>,] </a>
<a class="sourceLine" id="cb75-3" data-line-number="3"><span class="co">#&gt; Document-feature matrix of: 2 documents, 797 features (72.0% sparse).</span></a>
<a class="sourceLine" id="cb75-4" data-line-number="4"><span class="co">#&gt;        features</span></a>
<a class="sourceLine" id="cb75-5" data-line-number="5"><span class="co">#&gt; docs    morning government&#39;s cobr emergency committee coronavirus</span></a>
<a class="sourceLine" id="cb75-6" data-line-number="6"><span class="co">#&gt;   text1       1            2    1         1         1           3</span></a>
<a class="sourceLine" id="cb75-7" data-line-number="7"><span class="co">#&gt;   text3       0            0    1         3         0           1</span></a>
<a class="sourceLine" id="cb75-8" data-line-number="8"><span class="co">#&gt;        features</span></a>
<a class="sourceLine" id="cb75-9" data-line-number="9"><span class="co">#&gt; docs    outbreak first scotland minister</span></a>
<a class="sourceLine" id="cb75-10" data-line-number="10"><span class="co">#&gt;   text1        5     4        1        3</span></a>
<a class="sourceLine" id="cb75-11" data-line-number="11"><span class="co">#&gt;   text3        0     1        0        0</span></a>
<a class="sourceLine" id="cb75-12" data-line-number="12"><span class="co">#&gt; [ reached max_nfeat ... 787 more features ]</span></a></code></pre></div>
</div>
<div id="macron-2" class="section level2">
<h2><span class="header-section-number">6.2</span> Macron</h2>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb76-1" data-line-number="1">speech.coo.macron&lt;-<span class="kw">fcm</span>(corpus_macron,<span class="dt">context=</span><span class="st">&quot;window&quot;</span>,<span class="dt">window=</span><span class="dv">5</span>, <span class="dt">tri=</span><span class="ot">FALSE</span>)</a></code></pre></div>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb77-1" data-line-number="1">p&lt;-<span class="dv">2</span> <span class="co">#word embedding dimension</span></a>
<a class="sourceLine" id="cb77-2" data-line-number="2">speech.glove.macron&lt;-GlobalVectors<span class="op">$</span><span class="kw">new</span>(<span class="dt">rank =</span> p,<span class="dt">x_max =</span> <span class="dv">10</span>) <span class="co">#xmas is a neede technical option</span></a>
<a class="sourceLine" id="cb77-3" data-line-number="3">speech.weC.macron&lt;-speech.glove.macron<span class="op">$</span><span class="kw">fit_transform</span>(speech.coo.macron)</a>
<a class="sourceLine" id="cb77-4" data-line-number="4"><span class="co">#&gt; INFO  [12:20:26.610] epoch 1, loss 0.0247 </span></a>
<a class="sourceLine" id="cb77-5" data-line-number="5"><span class="co">#&gt; INFO  [12:20:26.619] epoch 2, loss 0.0179 </span></a>
<a class="sourceLine" id="cb77-6" data-line-number="6"><span class="co">#&gt; INFO  [12:20:26.628] epoch 3, loss 0.0163 </span></a>
<a class="sourceLine" id="cb77-7" data-line-number="7"><span class="co">#&gt; INFO  [12:20:26.639] epoch 4, loss 0.0152 </span></a>
<a class="sourceLine" id="cb77-8" data-line-number="8"><span class="co">#&gt; INFO  [12:20:26.648] epoch 5, loss 0.0145 </span></a>
<a class="sourceLine" id="cb77-9" data-line-number="9"><span class="co">#&gt; INFO  [12:20:26.658] epoch 6, loss 0.0136 </span></a>
<a class="sourceLine" id="cb77-10" data-line-number="10"><span class="co">#&gt; INFO  [12:20:26.672] epoch 7, loss 0.0130 </span></a>
<a class="sourceLine" id="cb77-11" data-line-number="11"><span class="co">#&gt; INFO  [12:20:26.680] epoch 8, loss 0.0123 </span></a>
<a class="sourceLine" id="cb77-12" data-line-number="12"><span class="co">#&gt; INFO  [12:20:26.689] epoch 9, loss 0.0118 </span></a>
<a class="sourceLine" id="cb77-13" data-line-number="13"><span class="co">#&gt; INFO  [12:20:26.704] epoch 10, loss 0.0114</span></a></code></pre></div>
<p>For illustration purpose, we now plot the 50 most used terms</p>
<p><a href="word-embedding.html#fig:speech-we-macron">6.3</a></p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb78-1" data-line-number="1">n.w.macron&lt;-<span class="kw">apply</span>(corpus_macron.dfm,<span class="dv">2</span>,sum) <span class="co">#compute the number of times each term is used</span></a>
<a class="sourceLine" id="cb78-2" data-line-number="2">index&lt;-<span class="kw">order</span>(n.w.macron,<span class="dt">decreasing =</span> <span class="ot">TRUE</span>)[<span class="dv">1</span><span class="op">:</span><span class="dv">50</span>]</a>
<a class="sourceLine" id="cb78-3" data-line-number="3"><span class="kw">plot</span>(speech.weC.macron[index,],<span class="dt">type =</span> <span class="st">&quot;n&quot;</span>,<span class="dt">xlab =</span> <span class="st">&quot;Dimension 1&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Dimendion 2&quot;</span>)</a>
<a class="sourceLine" id="cb78-4" data-line-number="4"><span class="kw">text</span>(<span class="dt">x=</span>speech.weC.macron[index,],<span class="dt">labels =</span> <span class="kw">rownames</span>(speech.weC.macron[index,]))</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:speech-we-macron"></span>
<img src="Text-Mining_files/figure-html/speech-we-macron-1.png" alt="The 50 most used terms" width="70%" />
<p class="caption">
Figure 6.3: The 50 most used terms
</p>
</div>
<p><a href="word-embedding.html#fig:dendogram-macron">6.4</a></p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb79-1" data-line-number="1">speech.dtm.macron &lt;-<span class="st"> </span>corpus_macron.dfm</a>
<a class="sourceLine" id="cb79-2" data-line-number="2">speech.rwmd.model.macron&lt;-RelaxedWordMoversDistance<span class="op">$</span><span class="kw">new</span>(corpus_macron.dfm,speech.weC.macron)</a>
<a class="sourceLine" id="cb79-3" data-line-number="3">speech.rwms.macron&lt;-speech.rwmd.model.macron<span class="op">$</span><span class="kw">sim2</span>(corpus_macron.dfm)</a>
<a class="sourceLine" id="cb79-4" data-line-number="4">speech.rwmd.macron&lt;-speech.rwmd.model.macron<span class="op">$</span><span class="kw">dist2</span>(corpus_macron.dfm)</a>
<a class="sourceLine" id="cb79-5" data-line-number="5"></a>
<a class="sourceLine" id="cb79-6" data-line-number="6">speech.hc.macron&lt;-<span class="kw">hclust</span>(<span class="kw">as.dist</span>(speech.rwmd.macron))</a>
<a class="sourceLine" id="cb79-7" data-line-number="7"><span class="kw">plot</span>(speech.hc.macron,<span class="dt">cex=</span><span class="fl">0.8</span>)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:dendogram-macron"></span>
<img src="Text-Mining_files/figure-html/dendogram-macron-1.png" alt="Cluser Dendogram" width="70%" />
<p class="caption">
Figure 6.4: Cluser Dendogram
</p>
</div>
<p>We can observe that there is some coherence within the groups in terms the date of the speech.</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb80-1" data-line-number="1">speech.cl.macron&lt;-<span class="st"> </span><span class="kw">cutree</span>(speech.hc.macron,<span class="dt">k=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb80-2" data-line-number="2">corpus_macron.dfm[speech.cl.macron<span class="op">==</span><span class="dv">1</span>,]</a>
<a class="sourceLine" id="cb80-3" data-line-number="3"><span class="co">#&gt; Document-feature matrix of: 2 documents, 1,366 features (45.8% sparse).</span></a>
<a class="sourceLine" id="cb80-4" data-line-number="4"><span class="co">#&gt;        features</span></a>
<a class="sourceLine" id="cb80-5" data-line-number="5"><span class="co">#&gt; docs    check delivery france dear past country spread virus</span></a>
<a class="sourceLine" id="cb80-6" data-line-number="6"><span class="co">#&gt;   text1     1        1      9    6    3       6      8    13</span></a>
<a class="sourceLine" id="cb80-7" data-line-number="7"><span class="co">#&gt;   text3     0        2      6    5    3      12      2    12</span></a>
<a class="sourceLine" id="cb80-8" data-line-number="8"><span class="co">#&gt;        features</span></a>
<a class="sourceLine" id="cb80-9" data-line-number="9"><span class="co">#&gt; docs    covid-19 several</span></a>
<a class="sourceLine" id="cb80-10" data-line-number="10"><span class="co">#&gt;   text1        4       5</span></a>
<a class="sourceLine" id="cb80-11" data-line-number="11"><span class="co">#&gt;   text3        1       5</span></a>
<a class="sourceLine" id="cb80-12" data-line-number="12"><span class="co">#&gt; [ reached max_nfeat ... 1,356 more features ]</span></a></code></pre></div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="topic-modelling.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="supervised-learning.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
