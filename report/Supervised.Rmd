# Supervised learning

In this section, we use a supervised learner to develop a classifier of the Politicans' speeches. The aim of this section is to have a classification model able to correctly attribute a random speech to Boris Johnson or Emmanuel Macron. To do so,  we first combine the dataframe of Boris Johnson with the dataframe of Emmanuel Macron. Since those dataframes differ in number of speechs and in length, we divide the speeches into sentences, which would smooth difference between our two dependent outcome possibilities.

```{r,warning=FALSE}

##Boris Johnson
boris_2<-as_tibble(c(boris9mars,boris12mars,boris16mars,boris18mars,boris19mars,boris20mars,boris22mars)) %>%
  rename(
  text=value)
author="Boris Johnson"
boris_supervised<- cbind(boris_2, author)

boris_2_sentence<-get_sentences(boris_supervised)
##Emmanuel Macron
Macron_2<-as_tibble(c(macron12march,macron16march,macron13april)) %>% 
  rename(
    text = value)

author="Macron"
macron_supervised<- cbind(Macron_2, author)

macron_2_sentence<-get_sentences(macron_supervised)

##Combine the 2 dataframes
combine <- rbind(boris_2_sentence, macron_2_sentence)


## Tokenization
combine_corpus<-corpus(combine)
combine_tokens<- tokens(combine_corpus, remove_numbers = TRUE, remove_punct = TRUE, remove_symbols = TRUE, remove_separators = TRUE)

##combi Lemmatization


combine_tokens <- tokens_replace(combine_tokens, pattern=hash_lemmas$token, replacement = hash_lemmas$lemma)


## Cleaning
combine_tokens = combine_tokens %>% 
  tokens_tolower() %>% 
  tokens_remove(stopwords("english"))

y<-factor(docvars(combine_tokens,"author"))

```

Then, we build the featues. To this aim, we first compute the DTM matrix.

```{r,warning=FALSE}
combine.dfm<-dfm(combine_tokens)
combine.dfm

```

## LSA

Because of the huge number of tokens, the feature matrix obtained may be too big to train a model in a reasonable amount of time. We thus apply a reduction dimension technque in order to obtain less features while keeping the relevant information. LSA is the perfect technique to achieve this. We target 30 dimensions (30 subjects)
```{r,warning=FALSE}

combine_corpus.dfm <- dfm(combine_corpus)
cmod<-textmodel_lsa(combine_corpus.dfm,nd=30)

```

## Random forest

After preparing our data to be used by the learner, we decide to run a random forest, which is a robust method to find the best classification model by computing a large set of classification tree to obtain the most pertinent values of classification criterias.
After building our model, we create a training and a test sets. In this simple context, in order to illustrate the concepts without too long computation times, we will limit ourselves to just one training set and one test set by applying the Pareto law 80-20. 

```{r,warning=FALSE}
set.seed(782)
df<-data.frame(Class=y, x=cmod$docs)
index.tr<-sample(size = round(0.8*length(y)),x=c(1:length(y)),replace = FALSE)

df.tr<-df[index.tr,]
df.te<-df[-index.tr,]


combine.fit<-ranger(Class~.,
                    data = df.tr)
pred.te<-predict(combine.fit,df.te)

```

In order to see the prediction quality of the model, we call the confusionMatrix function in the caret package:

```{r,warning=FALSE}

confusionMatrix<-confusionMatrix(data=pred.te$predictions,reference = df.te$Class)
confusionMatrix
```

The model has an accuracy of 77.3%, is is a quite poor accuracy, but enough good for a first try.
Butâ€¦ if we have a look one the sensitivity ( which is the % of predict the positive class, here this is Boris johnson) it is only 44.2%. 
So, we have a good model in order to predict the speech of Macon, about 94%, but much less to predict Boris Johnson. 


## Improving the features

In order to improve the accuracy, we look to improve the features construction. We may consider the elements fo feature construction as hyperparameters to be optimized. Therefore we compare differents dimensions with their corresponding accuracy. In the figure \@ref(fig:accuracy), we notice that with a dimension of 100, the accuracy will get higher than 84% !

```{r accuracy,fig.cap="Accuracy"}
nd.vec<-c(2,5,25,50,100,500,1000)
acc.vec<-numeric(length(nd.vec))
for (j in 1:length(nd.vec)) {
  cmod<-textmodel_lsa(combine_corpus.dfm,nd=nd.vec[j])
  df<-data.frame(class=y,x=cmod$docs)
  df.tr<-df[index.tr,]
  df.te<-df[-index.tr,]
  
  combine.fit<-ranger(class~.,
                    data = df.tr)
pred.te<-predict(combine.fit,df.te)
acc.vec[j]<-confusionMatrix(data=pred.te$predictions,reference = df.te$class)$overall[1]
  
}
acc.vec

plot(acc.vec~nd.vec,type="b")

```

```{r,warning=FALSE}
set.seed(788)
combine_corpus.dfm <- dfm(combine_corpus)
cmod<-textmodel_lsa(combine_corpus.dfm,nd=100)

df<-data.frame(class=y, x=cmod$docs)
index.tr<-sample(size = round(0.8*length(y)),x=c(1:length(y)),replace = FALSE)

df.tr<-df[index.tr,]
df.te<-df[-index.tr,]


combine.fit<-ranger(class~.,
                    data = df.tr)
pred.te<-predict(combine.fit,df.te)

confusionmatrix_2<-confusionMatrix(data=pred.te$predictions,reference = df.te$class)
confusionmatrix_2
```

By re-running the same model but by increasing dimensions rather than weighting the sentences, we observe an increase in accuracy,now the accuracy is 85.1%. Sensitivity has improved by 18.50% but the learner has a still a poor prediction ability, in spite of the increase of the dimensions.The improvement by weighting the independent variables would be potentially more efficient. We would keep it as being part of further investigations.
